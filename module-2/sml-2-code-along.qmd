---
title: "How to Split Data into Training and Testing Sets"
subtitle: "Code Along"
format:
  revealjs: 
    slide-number: c/t
    progress: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: img/LASERLogoB.png
    theme: [default, css/laser.scss]
    width: 1920
    height: 1080
    margin: 0.05
    footer: <a href=https://www.go.ncsu.edu/laser-institute>go.ncsu.edu/laser-institute
---

```{r}
#| include: false
```

```{r}
#| echo: false
# then load all the relevant packages
pacman::p_load(pacman, knitr, tidyverse, readxl)
```

# Getting started

## Process

- Again, create a .R file in `/module-2`
- Then, run copy and paste the code in this presentation as we talk through each step

## Quick discussion

- What's the function of the training data relative to the testing data?
- Which parts of the supervised machine learning process is most unclear?

# Code-along

## R Code

::: {.panel-tabset}

## 0

**Loading, setting up**

```{r}
#| eval: false
#| echo: true
library(tidyverse)
library(tidymodels)

starwars_recoded <- starwars %>% # built-in data available just by typing
    mutate(species_human = ifelse(species == "Human", "Human", "Not human")) # recoding species to create a categorical variable

starwars_recoded %>% 
    count(species) # how many humans are there?
```

## 1

**Split data**

```{r}
#| echo: true
#| eval: false
train_test_split <- initial_split(starwars_recoded, prop = .80, strata = "species_human")
data_train <- training(train_test_split)
data_test <- testing(train_test_split)
```

## 2

**Engineer features**

```{r}
#| echo: true
#| eval: false
# predicting humans based on the independent effects of height and mass
my_rec <- recipe(species_human ~ height + mass, data = data_train)
```

## 3

**Specify recipe, model, and workflow**

```{r}
#| echo: true
#| eval: false
# specify model
my_mod <- logistic_reg() %>%
    set_engine("glm") %>%
    set_mode("classification")

# specify workflow
my_wf <- workflow() %>%
   add_model(my_mod) %>% 
    add_recipe(my_rec)
```

## 4

**Fit model**

```{r}
#| echo: true
#| eval: false

final_fit <- last_fit(my_wf, train_test_split)
```

## 5

**Evaluate accuracy**

```{r}
#| echo: true
#| eval: false
final_fit %>%
   collect_metrics()
```

:::

## python code

```{python}
#| eval: false
#| echo: true

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# Load and preprocess the data
starwars = pd.read_csv('path_to_starwars.csv')  # Load your data file
starwars['species_human'] = starwars['species'].apply(lambda x: 'Human' if x == 'Human' else 'Not human')

# Split data
train, test = train_test_split(starwars, test_size=0.2, random_state=42)
X_train, y_train = train[['height', 'mass']], train['species_human']
X_test, y_test = test[['height', 'mass']], test['species_human']

# Specify model and fit
clf = LogisticRegression()
clf.fit(X_train, y_train)

# Evaluate accuracy
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
```

# Discussion

- What do you notice about the differences in the output between regression and SML?
- What do you notice is different about the modeling approach?