---
title: "How to Cross-Validate and Change the Model"
subtitle: "Code Along"
format:
  revealjs: 
    slide-number: c/t
    progress: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: img/LASERLogoB.png
    theme: [default, css/laser.scss]
    width: 1920
    height: 1080
    margin: 0.05
    footer: <a href=https://www.go.ncsu.edu/laser-institute>go.ncsu.edu/laser-institute
---

```{r}
# load all the relevant packages
pacman::p_load(pacman, knitr, tidyverse, readxl)
```

# Getting started

## Process

- Again, create a .R file in `/module-4`
- Then, run copy and paste the code in this presentation as we talk through each step

## Quick discussion

- Which feature engineering steps do you think are most important for the OULAD data we have been using?

# Code-along: R

::: {.panel-tabset}
## ggplot2

```{r}
#| eval: false
#| echo: true
library(ggrepel)
library(tidyverse)

ggplot(starwars, aes(x = height, label = name)) +
    geom_histogram()
```

## ggplot2 (2)

```{r}
#| eval: false
#| echo: true
library(ggrepel)

ggplot(starwars, aes(x = height, y = mass, label = name)) +
    geom_point() +
    geom_label_repel()
```

## vfcv

```{r}
#| eval: false
#| echo: true
library(tidymodels)

# during Step 1
kfcv <- vfold_cv(data_train, v = 20) # this differentiates this from what we did before
# before, we simple used data_train to fit our model
kfcv
```

## vfcv (2)

```{r}
#| eval: false
#| echo: true
# during step 3
my_mod <- rand_forest() %>% # different
    set_engine("ranger", importance = "impurity") %>% # different and with importance
    set_mode("classification")
```

## vfcv (3)

```{r}
#| eval: false
#| echo: true
fitted_model_resamples <- fit_resamples(my_wf, 
                                        resamples = vfcv, # different
                                        metrics = class_metrics) # instead of fit()
```

## vfcv (4)

```{r}
#| eval: false
#| echo: true
collect_metrics(fitted_model_resamples)
```

## vip

```{r}
#| eval: false
#| echo: true
# during Step 5
final_fit %>% 
    pluck(".workflow", 1) %>%   
    pull_workflow_fit() %>% 
    vip(num_features = 10)
```

:::

# Code-along: python

::: panel-tabset

## Loading, setting up

```{python}
# Imports for visualization and modeling
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import cross_val_score, KFold
from sklearn.ensemble import RandomForestClassifier
import shap

# Star Wars data
import seaborn as sns
starwars = sns.load_dataset('starwars')
```

## Plotting with matplotlib

```{python}
# Star Wars data
import seaborn as sns
starwars = sns.load_dataset('starwars')

# Plot 1: Histogram
plt.figure(figsize=(10, 6))
sns.histplot(starwars['height'], kde=False)
plt.xlabel('Height')
plt.ylabel('Count')
plt.title('Distribution of Heights')
plt.show()

# Plot 2: Scatter plot with labels
plt.figure(figsize=(10, 6))
sns.scatterplot(data=starwars, x='height', y='mass')
for i, txt in enumerate(starwars['name']):
    plt.annotate(txt, (starwars['height'][i], starwars['mass'][i]), fontsize=9)
plt.xlabel('Height')
plt.ylabel('Mass')
plt.title('Height vs Mass with Labels')
plt.show()
```

## Cross-validation and RF modeling

```{python}
# Cross-validation setup (v-fold)
from sklearn.datasets import make_classification
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
kf = KFold(n_splits=20, shuffle=True, random_state=42)
kf_splits = list(kf.split(X))

# Random Forest Model
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Cross-validation and metric collection
cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')
print('Cross-validation accuracy scores:', cv_scores)
print('Mean cross-validation accuracy:', cv_scores.mean())

# Fit the model on the entire dataset for feature importance
model.fit(X, y)
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X)

# Plot feature importance
shap.summary_plot(shap_values, X, plot_type="bar", max_display=10)
```